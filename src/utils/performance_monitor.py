#!/usr/bin/env python3
"""
ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ãƒ»æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ  - Phase 2.4
ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–ã€å‡¦ç†æœ€é©åŒ–ã€è² è·åˆ¶å¾¡ã‚’æä¾›
"""

import asyncio
import time
import psutil
import threading
import logging
from pathlib import Path
from typing import Dict, Any, List, Optional, Callable, Union
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from collections import deque, defaultdict
import json
import functools
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import weakref

@dataclass
class PerformanceMetric:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™"""
    name: str
    value: float
    unit: str
    timestamp: datetime = field(default_factory=datetime.now)
    category: str = "general"
    context: Dict[str, Any] = field(default_factory=dict)

@dataclass
class ResourceUsage:
    """ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡"""
    cpu_percent: float
    memory_percent: float
    memory_used_mb: float
    disk_usage_percent: float
    disk_free_gb: float
    network_bytes_sent: int = 0
    network_bytes_recv: int = 0
    timestamp: datetime = field(default_factory=datetime.now)

@dataclass
class PerformanceThresholds:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹é–¾å€¤"""
    max_cpu_percent: float = 80.0
    max_memory_percent: float = 85.0
    max_disk_percent: float = 90.0
    max_execution_time: float = 30.0
    max_concurrent_tasks: int = 5

class PerformanceCache:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã®ãŸã‚ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, max_size: int = 1000, ttl_seconds: int = 300):
        self.max_size = max_size
        self.ttl_seconds = ttl_seconds
        self._cache: Dict[str, Any] = {}
        self._timestamps: Dict[str, datetime] = {}
        self._access_counts: Dict[str, int] = defaultdict(int)
        self._lock = threading.RLock()
    
    def get(self, key: str) -> Optional[Any]:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥å–å¾—"""
        with self._lock:
            if key not in self._cache:
                return None
            
            # TTL ãƒã‚§ãƒƒã‚¯
            if datetime.now() - self._timestamps[key] > timedelta(seconds=self.ttl_seconds):
                self._remove(key)
                return None
            
            self._access_counts[key] += 1
            return self._cache[key]
    
    def set(self, key: str, value: Any) -> None:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥è¨­å®š"""
        with self._lock:
            # ã‚µã‚¤ã‚ºåˆ¶é™ãƒã‚§ãƒƒã‚¯
            if len(self._cache) >= self.max_size and key not in self._cache:
                self._evict_least_used()
            
            self._cache[key] = value
            self._timestamps[key] = datetime.now()
            self._access_counts[key] = 1
    
    def _remove(self, key: str) -> None:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥å‰Šé™¤"""
        self._cache.pop(key, None)
        self._timestamps.pop(key, None)
        self._access_counts.pop(key, None)
    
    def _evict_least_used(self) -> None:
        """æœ€å°‘ä½¿ç”¨ã‚¢ã‚¤ãƒ†ãƒ ã‚’å‰Šé™¤"""
        if not self._cache:
            return
        
        least_used_key = min(self._access_counts.items(), key=lambda x: x[1])[0]
        self._remove(least_used_key)
    
    def clear_expired(self) -> int:
        """æœŸé™åˆ‡ã‚Œã‚¢ã‚¤ãƒ†ãƒ ã‚’ã‚¯ãƒªã‚¢"""
        with self._lock:
            expired_keys = [
                key for key, timestamp in self._timestamps.items()
                if datetime.now() - timestamp > timedelta(seconds=self.ttl_seconds)
            ]
            
            for key in expired_keys:
                self._remove(key)
            
            return len(expired_keys)
    
    def get_stats(self) -> Dict[str, Any]:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆ"""
        with self._lock:
            return {
                "size": len(self._cache),
                "max_size": self.max_size,
                "hit_rate": sum(self._access_counts.values()) / max(len(self._cache), 1),
                "expired_items": self.clear_expired()
            }

class TaskQueue:
    """è² è·åˆ¶å¾¡ã®ãŸã‚ã®ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼"""
    
    def __init__(self, max_concurrent: int = 5, max_queue_size: int = 100):
        self.max_concurrent = max_concurrent
        self.max_queue_size = max_queue_size
        self.semaphore = asyncio.Semaphore(max_concurrent)
        self.queue = asyncio.Queue(maxsize=max_queue_size)
        self.active_tasks = set()
        self.completed_tasks = 0
        self.failed_tasks = 0
        self._running = False
    
    async def start(self):
        """ã‚­ãƒ¥ãƒ¼å‡¦ç†é–‹å§‹"""
        self._running = True
        asyncio.create_task(self._process_queue())
    
    async def stop(self):
        """ã‚­ãƒ¥ãƒ¼å‡¦ç†åœæ­¢"""
        self._running = False
        await self.queue.put(None)  # çµ‚äº†ã‚·ã‚°ãƒŠãƒ«
    
    async def submit(self, coro_func: Callable, *args, **kwargs) -> Any:
        """ã‚¿ã‚¹ã‚¯æŠ•å…¥"""
        if self.queue.qsize() >= self.max_queue_size:
            raise asyncio.QueueFull("Task queue is full")
        
        future = asyncio.Future()
        await self.queue.put((coro_func, args, kwargs, future))
        return await future
    
    async def _process_queue(self):
        """ã‚­ãƒ¥ãƒ¼å‡¦ç†"""
        while self._running:
            try:
                item = await self.queue.get()
                if item is None:  # çµ‚äº†ã‚·ã‚°ãƒŠãƒ«
                    break
                
                coro_func, args, kwargs, future = item
                asyncio.create_task(self._execute_task(coro_func, args, kwargs, future))
                
            except Exception as e:
                logging.error(f"Queue processing error: {e}")
    
    async def _execute_task(self, coro_func: Callable, args: tuple, kwargs: dict, future: asyncio.Future):
        """ã‚¿ã‚¹ã‚¯å®Ÿè¡Œ"""
        async with self.semaphore:
            task_id = id(future)
            self.active_tasks.add(task_id)
            
            try:
                result = await coro_func(*args, **kwargs)
                future.set_result(result)
                self.completed_tasks += 1
                
            except Exception as e:
                future.set_exception(e)
                self.failed_tasks += 1
                
            finally:
                self.active_tasks.discard(task_id)
    
    def get_stats(self) -> Dict[str, Any]:
        """ã‚­ãƒ¥ãƒ¼çµ±è¨ˆ"""
        return {
            "queue_size": self.queue.qsize(),
            "active_tasks": len(self.active_tasks),
            "completed_tasks": self.completed_tasks,
            "failed_tasks": self.failed_tasks,
            "max_concurrent": self.max_concurrent
        }

class PerformanceMonitor:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, 
                 logger: Optional[logging.Logger] = None,
                 thresholds: Optional[PerformanceThresholds] = None):
        self.logger = logger or self._setup_default_logger()
        self.thresholds = thresholds or PerformanceThresholds()
        self.metrics_history: deque = deque(maxlen=1000)
        self.resource_history: deque = deque(maxlen=100)
        self.execution_times: Dict[str, deque] = defaultdict(lambda: deque(maxlen=50))
        self.cache = PerformanceCache()
        self.task_queue = TaskQueue(max_concurrent=self.thresholds.max_concurrent_tasks)
        self.monitoring_active = False
        self.alert_callbacks: List[Callable] = []
        self._monitor_task = None
        
    def _setup_default_logger(self) -> logging.Logger:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ­ã‚¬ãƒ¼è¨­å®š"""
        logger = logging.getLogger('performance_monitor')
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            # ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ³ãƒ‰ãƒ©
            log_dir = Path(__file__).parent.parent.parent / "logs"
            log_dir.mkdir(exist_ok=True)
            
            fh = logging.FileHandler(log_dir / 'performance.log')
            fh.setLevel(logging.INFO)
            
            # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            fh.setFormatter(formatter)
            logger.addHandler(fh)
        
        return logger
    
    async def start_monitoring(self, interval_seconds: float = 5.0):
        """ç›£è¦–é–‹å§‹"""
        if self.monitoring_active:
            return
        
        self.monitoring_active = True
        await self.task_queue.start()
        
        self._monitor_task = asyncio.create_task(
            self._monitoring_loop(interval_seconds)
        )
        
        self.logger.info("ğŸš€ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–é–‹å§‹")
    
    async def stop_monitoring(self):
        """ç›£è¦–åœæ­¢"""
        if not self.monitoring_active:
            return
        
        self.monitoring_active = False
        
        if self._monitor_task:
            self._monitor_task.cancel()
            try:
                await self._monitor_task
            except asyncio.CancelledError:
                pass
        
        await self.task_queue.stop()
        self.logger.info("ğŸ›‘ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–åœæ­¢")
    
    async def _monitoring_loop(self, interval: float):
        """ç›£è¦–ãƒ«ãƒ¼ãƒ—"""
        while self.monitoring_active:
            try:
                # ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡å–å¾—
                resource_usage = self._get_resource_usage()
                self.resource_history.append(resource_usage)
                
                # é–¾å€¤ãƒã‚§ãƒƒã‚¯
                self._check_thresholds(resource_usage)
                
                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                self.cache.clear_expired()
                
                await asyncio.sleep(interval)
                
            except Exception as e:
                self.logger.error(f"Monitoring loop error: {e}")
                await asyncio.sleep(interval)
    
    def _get_resource_usage(self) -> ResourceUsage:
        """ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡å–å¾—"""
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        
        try:
            network = psutil.net_io_counters()
            network_sent = network.bytes_sent
            network_recv = network.bytes_recv
        except:
            network_sent = network_recv = 0
        
        return ResourceUsage(
            cpu_percent=cpu_percent,
            memory_percent=memory.percent,
            memory_used_mb=memory.used / (1024 * 1024),
            disk_usage_percent=disk.percent,
            disk_free_gb=disk.free / (1024 * 1024 * 1024),
            network_bytes_sent=network_sent,
            network_bytes_recv=network_recv
        )
    
    def _check_thresholds(self, resource_usage: ResourceUsage):
        """é–¾å€¤ãƒã‚§ãƒƒã‚¯"""
        alerts = []
        
        if resource_usage.cpu_percent > self.thresholds.max_cpu_percent:
            alerts.append(f"é«˜CPUä½¿ç”¨ç‡: {resource_usage.cpu_percent:.1f}%")
        
        if resource_usage.memory_percent > self.thresholds.max_memory_percent:
            alerts.append(f"é«˜ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡: {resource_usage.memory_percent:.1f}%")
        
        if resource_usage.disk_usage_percent > self.thresholds.max_disk_percent:
            alerts.append(f"ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ä¸è¶³: {resource_usage.disk_usage_percent:.1f}%")
        
        for alert in alerts:
            self.logger.warning(f"âš ï¸ {alert}")
            self._trigger_alert(alert, resource_usage)
    
    def _trigger_alert(self, message: str, resource_usage: ResourceUsage):
        """ã‚¢ãƒ©ãƒ¼ãƒˆç™ºç«"""
        for callback in self.alert_callbacks:
            try:
                callback(message, resource_usage)
            except Exception as e:
                self.logger.error(f"Alert callback error: {e}")
    
    def measure_execution_time(self, func_name: str = None):
        """å®Ÿè¡Œæ™‚é–“æ¸¬å®šãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿"""
        def decorator(func):
            name = func_name or func.__name__
            
            @functools.wraps(func)
            def wrapper(*args, **kwargs):
                start_time = time.time()
                try:
                    result = func(*args, **kwargs)
                    return result
                finally:
                    execution_time = time.time() - start_time
                    self._record_execution_time(name, execution_time)
            
            @functools.wraps(func)
            async def async_wrapper(*args, **kwargs):
                start_time = time.time()
                try:
                    result = await func(*args, **kwargs)
                    return result
                finally:
                    execution_time = time.time() - start_time
                    self._record_execution_time(name, execution_time)
            
            if asyncio.iscoroutinefunction(func):
                return async_wrapper
            else:
                return wrapper
        
        return decorator
    
    def _record_execution_time(self, func_name: str, execution_time: float):
        """å®Ÿè¡Œæ™‚é–“è¨˜éŒ²"""
        self.execution_times[func_name].append(execution_time)
        
        # é•·æ™‚é–“å®Ÿè¡Œã®è­¦å‘Š
        if execution_time > self.thresholds.max_execution_time:
            self.logger.warning(
                f"âš ï¸ é•·æ™‚é–“å®Ÿè¡Œ: {func_name} ({execution_time:.2f}s)"
            )
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²
        metric = PerformanceMetric(
            name=f"{func_name}_execution_time",
            value=execution_time,
            unit="seconds",
            category="execution_time"
        )
        self.metrics_history.append(metric)
    
    async def optimize_concurrent_screenshots(self, 
                                             screenshot_tasks: List[Callable],
                                             max_concurrent: int = None) -> List[Any]:
        """ä¸¦åˆ—ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆæœ€é©åŒ–"""
        max_concurrent = max_concurrent or self.thresholds.max_concurrent_tasks
        
        # ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡ã«åŸºã¥ãå‹•çš„èª¿æ•´
        current_usage = self._get_resource_usage()
        if current_usage.cpu_percent > 70:
            max_concurrent = max(1, max_concurrent // 2)
        elif current_usage.memory_percent > 80:
            max_concurrent = max(1, max_concurrent // 3)
        
        self.logger.info(f"ğŸ“¸ ä¸¦åˆ—ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆå®Ÿè¡Œ: {len(screenshot_tasks)}ã‚¿ã‚¹ã‚¯, ä¸¦åˆ—åº¦: {max_concurrent}")
        
        # ã‚»ãƒãƒ•ã‚©ã§ä¸¦åˆ—åº¦åˆ¶å¾¡
        semaphore = asyncio.Semaphore(max_concurrent)
        
        async def controlled_task(task):
            async with semaphore:
                return await task()
        
        # ä¸¦åˆ—å®Ÿè¡Œ
        start_time = time.time()
        results = await asyncio.gather(
            *[controlled_task(task) for task in screenshot_tasks],
            return_exceptions=True
        )
        execution_time = time.time() - start_time
        
        # çµæœåˆ†æ
        successful = len([r for r in results if not isinstance(r, Exception)])
        failed = len(results) - successful
        
        self.logger.info(
            f"âœ… ä¸¦åˆ—ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆå®Œäº†: {successful}æˆåŠŸ, {failed}å¤±æ•—, "
            f"å®Ÿè¡Œæ™‚é–“: {execution_time:.2f}s"
        )
        
        return results
    
    def add_alert_callback(self, callback: Callable):
        """ã‚¢ãƒ©ãƒ¼ãƒˆã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯è¿½åŠ """
        self.alert_callbacks.append(callback)
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¦ç´„å–å¾—"""
        if not self.resource_history:
            return {"status": "no_data"}
        
        recent_resources = list(self.resource_history)[-10:]
        avg_cpu = sum(r.cpu_percent for r in recent_resources) / len(recent_resources)
        avg_memory = sum(r.memory_percent for r in recent_resources) / len(recent_resources)
        
        execution_stats = {}
        for func_name, times in self.execution_times.items():
            if times:
                execution_stats[func_name] = {
                    "avg_time": sum(times) / len(times),
                    "max_time": max(times),
                    "min_time": min(times),
                    "call_count": len(times)
                }
        
        return {
            "status": "active" if self.monitoring_active else "inactive",
            "resource_usage": {
                "avg_cpu_percent": avg_cpu,
                "avg_memory_percent": avg_memory,
                "current_cpu": recent_resources[-1].cpu_percent,
                "current_memory": recent_resources[-1].memory_percent,
            },
            "execution_times": execution_stats,
            "cache_stats": self.cache.get_stats(),
            "task_queue_stats": self.task_queue.get_stats(),
            "metrics_count": len(self.metrics_history),
            "thresholds": {
                "max_cpu": self.thresholds.max_cpu_percent,
                "max_memory": self.thresholds.max_memory_percent,
                "max_execution_time": self.thresholds.max_execution_time
            }
        }
    
    def export_metrics(self, file_path: str):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        data = {
            "performance_summary": self.get_performance_summary(),
            "resource_history": [
                {
                    "timestamp": r.timestamp.isoformat(),
                    "cpu_percent": r.cpu_percent,
                    "memory_percent": r.memory_percent,
                    "disk_percent": r.disk_usage_percent
                }
                for r in self.resource_history
            ],
            "metrics_history": [
                {
                    "name": m.name,
                    "value": m.value,
                    "unit": m.unit,
                    "timestamp": m.timestamp.isoformat(),
                    "category": m.category
                }
                for m in self.metrics_history
            ]
        }
        
        Path(file_path).write_text(json.dumps(data, indent=2, ensure_ascii=False))
        self.logger.info(f"ğŸ“Š ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†: {file_path}")

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¢ãƒ‹ã‚¿ãƒ¼
_global_performance_monitor = None

def get_global_performance_monitor() -> PerformanceMonitor:
    """ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¢ãƒ‹ã‚¿ãƒ¼å–å¾—"""
    global _global_performance_monitor
    if _global_performance_monitor is None:
        _global_performance_monitor = PerformanceMonitor()
    return _global_performance_monitor

# ä¾¿åˆ©ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿
def monitor_performance(func_name: str = None):
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿"""
    monitor = get_global_performance_monitor()
    return monitor.measure_execution_time(func_name)

# ãƒ†ã‚¹ãƒˆé–¢æ•°
async def test_performance_monitor():
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¢ãƒ‹ã‚¿ãƒ¼ãƒ†ã‚¹ãƒˆ"""
    monitor = PerformanceMonitor()
    
    await monitor.start_monitoring(interval_seconds=1)
    
    # ãƒ†ã‚¹ãƒˆç”¨é‡ã„å‡¦ç†
    @monitor.measure_execution_time("test_heavy_task")
    async def heavy_task():
        await asyncio.sleep(2)
        return "completed"
    
    # ä¸¦åˆ—ãƒ†ã‚¹ãƒˆ
    tasks = [heavy_task for _ in range(3)]
    results = await monitor.optimize_concurrent_screenshots(tasks, max_concurrent=2)
    
    # çµ±è¨ˆè¡¨ç¤º
    summary = monitor.get_performance_summary()
    print(json.dumps(summary, indent=2, ensure_ascii=False))
    
    await monitor.stop_monitoring()

if __name__ == "__main__":
    asyncio.run(test_performance_monitor())